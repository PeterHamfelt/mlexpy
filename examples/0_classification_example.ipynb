{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example `mlxpy` usage on the iris dataset for multi-class classification using a RandomForest and SGDClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load the dataset, models, and mlexpy modules...\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import load_iris\n",
    "from mlexpy import experiment, pipeline_utils, processor\n",
    "\n",
    "from typing import List, Optional, Union, Callable, Type\n",
    "\n",
    "# load a random forest and sgd classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# and numpy, pandas\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, an example of the general method flow with `mlexpy` (as described in the `README`):\n",
    "1. Load in the dataset\n",
    "2. Create your training and testing set split -- this results in an imutable named tuple structure termed an `ExperimentSetup`, this is made up of 2 `MLSetup` named tuples. Each `MLSetup` named tuple has 2 attributes, a `.obs` attribute,  and a `.labels` attribute. In essence the `.obs` attribute is your feature set (in `mlexpy` this is a pandas DataFrame, and the `.labels` is a pandas Series). An `ExperimentSetup` thus contains an `MLSetup` to use for training, and an `MLSetup` to use _purely_ for testing. This is meant to simply, and in pythonic clear language differentiate the training data (as `ExpiramentSetup.training_data`) and the test data (`ExperimentSetup.test_data`).\n",
    "    - Note: `mlexpy` defers to using a stratified train test split to retain class imbalance / class proporting in training at testing.\n",
    "3. Defing a class to do the data processing / feature engineering that inherits the `mlexpy.processor.ProcessPipelineBase` class; and a class to do the model training that inherits the `mlexpy.expirament.ClassifierExpiramentBase` class. (The explicit notebook cells will better outline this usage.)\n",
    "\n",
    "    - `mlexpy` operates in an object oriented framework. These baseclasses are built to carry a large amount of convieneint, clear, and reproducable behavior.\n",
    "\n",
    "4. Perform your feature engineering, and perform your model training.\n",
    "5. Evaluate your model.\n",
    "\n",
    "### (1) We will see how this works with all of your dev in a jupyter notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    0\n",
      "sepal width (cm)     0\n",
      "petal length (cm)    0\n",
      "petal width (cm)     0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# First, set the random seed(s) for the exprament\n",
    "MODEL_SEED = 10\n",
    "PROCESS_SEED = 100\n",
    "\n",
    "model_rs = np.random.RandomState(MODEL_SEED)\n",
    "\n",
    "# First, read in the dataset as a dataframe. Because mlexpy is meant to be an exploratory/experimental tool, \n",
    "# dataframes are preferred for their readability.\n",
    "data = load_iris(as_frame=True)\n",
    "features = data[\"data\"]\n",
    "labels = data[\"target\"]\n",
    "\n",
    "# We want to look at the dataset for any faulty records...\n",
    "print(features.isna().sum())\n",
    "\n",
    "# Spoiler -- there are none in the features. Next look in the labels...\n",
    "print(labels.isna().sum())\n",
    "\n",
    "# Spoiler -- none again, so we use all data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels are 35.33% of the original data (97).\n",
      "Test labels are 64.67% of the original data (53).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, generate the ExperimentSetup object, that splits the dataset for training and testing.\n",
    "experiment_setup = pipeline_utils.get_stratified_train_test_data(train_data=features, label_data=labels, test_frac=0.35, random_state=PROCESS_SEED)\n",
    "\n",
    "# This provides us with a named tuple, with attributes of .train_data and .test_data \n",
    "# each one with attributes of .obs and .labels. For example...\n",
    "train_label_count = experiment_setup.train_data.labels.shape[0]\n",
    "test_label_count = experiment_setup.test_data.labels.shape[0]\n",
    "total_data_count = features.shape[0]\n",
    "\n",
    "print(f\"Train labels are {round((total_data_count - train_label_count) / total_data_count * 100, 2)}% of the original data ({train_label_count}).\")\n",
    "print(f\"Test labels are {round((total_data_count - test_label_count) / total_data_count * 100, 2)}% of the original data ({test_label_count}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, define the processing class. This inherits from the `ProcessPipelineBase` class. \n",
    "# For minimal functionality, this class simply needs the `.process_data()` method to be defined. Not adding \n",
    "# code for this class will result in a `NotImplementedError`.\n",
    "\n",
    "# The following shows an example of how to use this class:\n",
    "class IrisPipeline(processor.ProcessPipelineBase):\n",
    "    def __init__(self, \n",
    "        process_tag: str = \"iris_development\", \n",
    "        model_dir: Optional[Union[str, Path]] = None, \n",
    "        model_storage_function: Optional[Callable] = None, \n",
    "        model_loading_function: Optional[Callable] = None, \n",
    "        store_models: bool = True,\n",
    "        rand_int: int=10,\n",
    "        ) -> None:\n",
    "        super().__init__(process_tag, model_dir, model_storage_function, model_loading_function, store_models, rand_int)\n",
    "\n",
    "\n",
    "    # Now -- define the .process_data() method.\n",
    "    def process_data(self, df: pd.DataFrame, training: bool = True, label_series: Optional[pd.Series] = None) -> pd.DataFrame:\n",
    "        # Now, simply do all feature engineering in this method, and return the final data/feature set to perform\n",
    "        # predictions on.\n",
    "\n",
    "        # Imagine we have 1 desired feature to engineer, petal/sepal area, and then normalize the feature values.\n",
    "        # We need to pay attention in the normalizing step, because we can ONLY apply the normalize to the test\n",
    "        # set, thus we will have a fork in the process when doing the feature normalization. \n",
    "        \n",
    "        # In order to easily maintain reproducibility in data processing, any model based feature engineering (such\n",
    "        # as normalization) is done by creating a specific data structure storing the order of steps for processing each column, \n",
    "        # and the model that should be applied. This is somewhat similar to the ColumnTransformer in sklearn.\n",
    "\n",
    "        # Model based features are handled in the .fit_model_based_features() method, described below.\n",
    "         \n",
    "        # Lets begin:\n",
    "\n",
    "        # Do a copy of the passed df\n",
    "        df = df.copy()\n",
    "\n",
    "        # First, compute the petal / sepal areas (but make the columns simpler)\n",
    "        df.columns = [col.replace(\" \", \"_\").strip(\"_(cm)\") for col in df.columns]\n",
    "\n",
    "        for object in [\"petal\", \"sepal\"]:\n",
    "            df[f\"{object}_area\"] = df[f\"{object}_length\"] * df[f\"{object}_width\"]\n",
    "\n",
    "        # Now perform the training / testing dependent feature processing. This is why a `training` boolean is passed.\n",
    "        if training:\n",
    "            # Now FIT all of the model based features...\n",
    "            self.fit_model_based_features(df)\n",
    "            # ... and get the results of a transformation of all model based features.\n",
    "            model_features = self.transform_model_based_features(df)\n",
    "        else:\n",
    "            # Here we can ONLY apply the transformation\n",
    "            model_features = self.transform_model_based_features(df)\n",
    "\n",
    "        # Imagine we only want to use ONLY the scaled features for prediction, then we retrieve only the scaled columns.\n",
    "        # (This is easy because the columns are renamed with the model name in the column name)\n",
    "        prediction_df = model_features[[col for col in model_features if \"standardscaler\" in col.lower()]]\n",
    "\n",
    "        return prediction_df\n",
    "\n",
    "    def fit_model_based_features(self, df: pd.DataFrame) -> None:\n",
    "        # Here we do any processing of columns that will require a model based transformation / engineering.\n",
    "\n",
    "        # In this case, simply fit a standard (normalization) scaler to the numerical columns. \n",
    "        # This case will result in additional columns on the dataframe named as \n",
    "        # \"<original-column-name>_StandardScaler()\".\n",
    "\n",
    "        # Note: there are no returned values for this method, the result is an update in the self.column_transformations dictionary\n",
    "        for column in df.columns:\n",
    "            if df[column].dtype not in (\"float\", \"int\"):\n",
    "                continue\n",
    "            self.fit_scaler(df[column], standard_scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x1250d9700> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x1250d9700> to: /Users/NathanSankary/git/mlexpy/examples/iris_development/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_standardscaler</th>\n",
       "      <th>sepal_width_standardscaler</th>\n",
       "      <th>petal_length_standardscaler</th>\n",
       "      <th>petal_width_standardscaler</th>\n",
       "      <th>petal_area_standardscaler</th>\n",
       "      <th>sepal_area_standardscaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.077948</td>\n",
       "      <td>-0.898694</td>\n",
       "      <td>0.748068</td>\n",
       "      <td>0.898228</td>\n",
       "      <td>0.804410</td>\n",
       "      <td>-0.707603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.809650</td>\n",
       "      <td>-0.898694</td>\n",
       "      <td>0.067794</td>\n",
       "      <td>0.246071</td>\n",
       "      <td>-0.090103</td>\n",
       "      <td>-1.205176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.165953</td>\n",
       "      <td>-0.898694</td>\n",
       "      <td>0.748068</td>\n",
       "      <td>0.506934</td>\n",
       "      <td>0.480863</td>\n",
       "      <td>-0.541745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.541352</td>\n",
       "      <td>0.791648</td>\n",
       "      <td>-1.349444</td>\n",
       "      <td>-1.188672</td>\n",
       "      <td>-1.155906</td>\n",
       "      <td>-0.713746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-0.077948</td>\n",
       "      <td>-1.140172</td>\n",
       "      <td>0.124483</td>\n",
       "      <td>-0.014791</td>\n",
       "      <td>-0.229673</td>\n",
       "      <td>-0.885746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length_standardscaler  sepal_width_standardscaler  \\\n",
       "101                    -0.077948                   -0.898694   \n",
       "59                     -0.809650                   -0.898694   \n",
       "83                      0.165953                   -0.898694   \n",
       "6                      -1.541352                    0.791648   \n",
       "92                     -0.077948                   -1.140172   \n",
       "\n",
       "     petal_length_standardscaler  petal_width_standardscaler  \\\n",
       "101                     0.748068                    0.898228   \n",
       "59                      0.067794                    0.246071   \n",
       "83                      0.748068                    0.506934   \n",
       "6                      -1.349444                   -1.188672   \n",
       "92                      0.124483                   -0.014791   \n",
       "\n",
       "     petal_area_standardscaler  sepal_area_standardscaler  \n",
       "101                   0.804410                  -0.707603  \n",
       "59                   -0.090103                  -1.205176  \n",
       "83                    0.480863                  -0.541745  \n",
       "6                    -1.155906                  -0.713746  \n",
       "92                   -0.229673                  -0.885746  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As an example, lets look at the outputs of the `.process_data()` method.\n",
    "iris_processor = IrisPipeline(model_dir=Path.cwd(), rand_int=PROCESS_SEED)  # set the model path to the examples directory\n",
    "\n",
    "# now run the process_data method\n",
    "processed_df = iris_processor.process_data(df=experiment_setup.train_data.obs.copy(), training=True)\n",
    "\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.experiment:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.experiment:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples/example_development_process. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x10d6a9dc0> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x10d6a9dc0> to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x10d6a9dc0> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x10d6a9dc0> to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.experiment:Training over 6 features (Index(['sepal_length_standardscaler', 'sepal_width_standardscaler',\n",
      "       'petal_length_standardscaler', 'petal_width_standardscaler',\n",
      "       'petal_area_standardscaler', 'sepal_area_standardscaler'],\n",
      "      dtype='object')) and 97 examples.\n",
      "INFO:mlexpy.experiment:Performing standard model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data are of size (97, 6), the test data are (53, 6).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:Model trained\n"
     ]
    }
   ],
   "source": [
    "# Now, our \"work\" is done, lets pass our data through this process! Lets try using a randomforest model\n",
    "\n",
    "# Define the experiment\n",
    "experiment_obj = experiment.ClassifierExperiment(\n",
    "    train_setup=experiment_setup.train_data,\n",
    "    test_setup=experiment_setup.test_data,\n",
    "    cv_split_count=20,\n",
    "    model_tag=\"example_development_model\",\n",
    "    process_tag=\"example_development_process\",\n",
    "    model_dir=Path.cwd()\n",
    ")\n",
    "\n",
    "# Set the pipeline attribute to use\n",
    "experiment_obj.set_pipeline(IrisPipeline)\n",
    "\n",
    "# Now begin the experimentation, start with performing the data processing...\n",
    "processed_datasets = experiment_obj.process_data()\n",
    "\n",
    "# ... then train our model...\n",
    "trained_model = experiment_obj.train_model(\n",
    "    RandomForestClassifier(random_state=model_rs),  # This is why we have 2 different random states...\n",
    "    processed_datasets,\n",
    "    # model_algorithm.hyperparams,  # If this is passed, then cross validation search is performed, but slow.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The f1_macro score is: \n",
      " 0.8848684210526315.\n",
      "\n",
      "The f1_micro score is: \n",
      " 0.8867924528301887.\n",
      "\n",
      "The f1_weighted score is: \n",
      " 0.8856752730883812.\n",
      "\n",
      "The log_loss score is: \n",
      " 0.2254147567189913.\n",
      "\n",
      "The balanced_accuracy score is: \n",
      " 0.8877995642701525.\n",
      "\n",
      "The accuracy score is: \n",
      " 0.8867924528301887.\n",
      "\n",
      "The confusion_matrix score is: \n",
      " [[18  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  5 13]].\n",
      "\n",
      "The classification_report score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       0.76      0.94      0.84        17\n",
      "           2       0.93      0.72      0.81        18\n",
      "\n",
      "    accuracy                           0.89        53\n",
      "   macro avg       0.90      0.89      0.88        53\n",
      "weighted avg       0.90      0.89      0.89        53\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the predictions, ClassificationExperiment provides some standard classification metrics\n",
    "# and evaluations.\n",
    "\n",
    "# Get the predictions and evaluate the performance.\n",
    "predictions = experiment_obj.predict(processed_datasets, trained_model)\n",
    "class_probabilities = experiment_obj.predict(processed_datasets, trained_model, proba=True)\n",
    "results = experiment_obj.evaluate_predictions(\n",
    "    processed_datasets.test_data.labels,\n",
    "    predictions=predictions,\n",
    "    class_probabilities=class_probabilities,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Next, how this same process might look when developing as modules. \n",
    "We now use the exact same model and dataset, however use the imported modules as our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.experiment:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.experiment:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples/example_development_process. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x125128340> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x125128340> to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x125128340> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x125128340> to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.experiment:Training over 6 features (Index(['sepal_length_standardscaler', 'sepal_width_standardscaler',\n",
      "       'petal_length_standardscaler', 'petal_width_standardscaler',\n",
      "       'petal_area_standardscaler', 'sepal_area_standardscaler'],\n",
      "      dtype='object')) and 97 examples.\n",
      "INFO:mlexpy.experiment:Performing standard model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data are of size (97, 6), the test data are (53, 6).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:Model trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The f1_macro score is: \n",
      " 0.8848684210526315.\n",
      "\n",
      "The f1_micro score is: \n",
      " 0.8867924528301887.\n",
      "\n",
      "The f1_weighted score is: \n",
      " 0.8856752730883812.\n",
      "\n",
      "The log_loss score is: \n",
      " 0.2254147567189913.\n",
      "\n",
      "The balanced_accuracy score is: \n",
      " 0.8877995642701525.\n",
      "\n",
      "The accuracy score is: \n",
      " 0.8867924528301887.\n",
      "\n",
      "The confusion_matrix score is: \n",
      " [[18  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  5 13]].\n",
      "\n",
      "The classification_report score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       0.76      0.94      0.84        17\n",
      "           2       0.93      0.72      0.81        18\n",
      "\n",
      "    accuracy                           0.89        53\n",
      "   macro avg       0.90      0.89      0.88        53\n",
      "weighted avg       0.90      0.89      0.89        53\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# The only change is that we need to now import the classes we developed above classes.\n",
    "# Rename them for clarity of what is doing what\n",
    "from from_module_example import IrisPipeline as IrisPipeImport\n",
    "\n",
    "# First, reset our seeds...\n",
    "model_rs = np.random.RandomState(MODEL_SEED)\n",
    "\n",
    "\n",
    "# Define the experiment\n",
    "imported_experiment = experiment.ClassifierExperiment(\n",
    "    train_setup=experiment_setup.train_data,\n",
    "    test_setup=experiment_setup.test_data,\n",
    "    cv_split_count=20,\n",
    "    model_tag=\"example_development_model\",\n",
    "    process_tag=\"example_development_process\",\n",
    "    model_dir=Path.cwd()\n",
    ")\n",
    "\n",
    "# Set the pipeline to use\n",
    "imported_experiment.set_pipeline(IrisPipeImport)\n",
    "\n",
    "# Now begin the experimentation, start with performing the data processing...\n",
    "processed_datasets = imported_experiment.process_data()\n",
    "\n",
    "# ... then train the model...\n",
    "trained_model = imported_experiment.train_model(\n",
    "    RandomForestClassifier(random_state=model_rs),  # This is why we have 2 different random states...\n",
    "    processed_datasets,\n",
    "    # model_algorithm.hyperparams,  # If this is passed, then cross validation search is performed, but slow.\n",
    ")\n",
    "\n",
    "# Get the predictions and evaluate the performance.\n",
    "predictions = imported_experiment.predict(processed_datasets, trained_model)\n",
    "class_probabilities = imported_experiment.predict(processed_datasets, trained_model, proba=True)\n",
    "results = imported_experiment.evaluate_predictions(\n",
    "    processed_datasets.test_data.labels,\n",
    "    predictions=predictions,\n",
    "    class_probabilities=class_probabilities,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And you can se that we get the exact same results when using the imported modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Do the same process using this time and `SGDClassifier`\n",
    "\n",
    "This time, all we need to do is change the model that is passed when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.experiment:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.experiment:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples/example_development_process. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x125131e80> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x125131e80> to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x125131e80> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x125131e80> to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.experiment:Training over 6 features (Index(['sepal_length_standardscaler', 'sepal_width_standardscaler',\n",
      "       'petal_length_standardscaler', 'petal_width_standardscaler',\n",
      "       'petal_area_standardscaler', 'sepal_area_standardscaler'],\n",
      "      dtype='object')) and 97 examples.\n",
      "INFO:mlexpy.experiment:Performing standard model training.\n",
      "/Users/NathanSankary/.pyenv/versions/3.9.5/envs/test/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "INFO:mlexpy.experiment:Model trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data are of size (97, 6), the test data are (53, 6).\n",
      "\n",
      "The f1_macro score is: \n",
      " 0.8848684210526315.\n",
      "\n",
      "The f1_micro score is: \n",
      " 0.8867924528301887.\n",
      "\n",
      "The f1_weighted score is: \n",
      " 0.8856752730883812.\n",
      "\n",
      "The log_loss score is: \n",
      " 0.6366219976422687.\n",
      "\n",
      "The balanced_accuracy score is: \n",
      " 0.8877995642701525.\n",
      "\n",
      "The accuracy score is: \n",
      " 0.8867924528301887.\n",
      "\n",
      "The confusion_matrix score is: \n",
      " [[18  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  5 13]].\n",
      "\n",
      "The classification_report score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       0.76      0.94      0.84        17\n",
      "           2       0.93      0.72      0.81        18\n",
      "\n",
      "    accuracy                           0.89        53\n",
      "   macro avg       0.90      0.89      0.88        53\n",
      "weighted avg       0.90      0.89      0.89        53\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# The only change is that we need to now import the classes we developed above classes.\n",
    "# Rename them for clarity of what is doing what\n",
    "\n",
    "# Again, reset our seeds...\n",
    "model_rs = np.random.RandomState(MODEL_SEED)\n",
    "\n",
    "\n",
    "# Define the experiment\n",
    "imported_experiment = experiment.ClassifierExperiment(\n",
    "    train_setup=experiment_setup.train_data,\n",
    "    test_setup=experiment_setup.test_data,\n",
    "    cv_split_count=20,\n",
    "    model_tag=\"example_development_model\",\n",
    "    process_tag=\"example_development_process\",\n",
    "    model_dir=Path.cwd()\n",
    ")\n",
    "\n",
    "imported_experiment.set_pipeline(IrisPipeImport)\n",
    "# Now begin the experimentation, start with performing the data processing...\n",
    "processed_datasets = imported_experiment.process_data()\n",
    "\n",
    "# ... then train the model...\n",
    "trained_model = imported_experiment.train_model(\n",
    "    SGDClassifier(random_state=model_rs, loss=\"log\"),  # This is why we have 2 different random states...\n",
    "    processed_datasets,\n",
    "    # model_algorithm.hyperparams,  # If this is passed, then cross validation search is performed, but slow.\n",
    ")\n",
    "\n",
    "# Get the predictions and evaluate the performance.\n",
    "predictions = imported_experiment.predict(processed_datasets, trained_model)\n",
    "class_probabilities = imported_experiment.predict(processed_datasets, trained_model, proba=True)\n",
    "results = imported_experiment.evaluate_predictions(\n",
    "    processed_datasets.test_data.labels,\n",
    "    predictions=predictions,\n",
    "    class_probabilities=class_probabilities,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Now what if we wanted to use a different set of columns (ex. ALL cols not only the scaled columns)?\n",
    "We do that simply by re-defining the method to process our data. We can either, overwrite the method with the change, or compute a new process_data method for this specific case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.experiment:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.experiment:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples/example_development_process. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x12504f790> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x12504f790> to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length/0_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width/1_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length/2_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width/3_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area/4_standardscaler()\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Saving the StandardScaler() model using joblib.\n",
      "INFO:mlexpy.processor:Dumped StandardScaler() to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area/5_standardscaler()\n",
      "INFO:mlexpy.processor:Saving the <mlexpy.processor.FeatureReducer object at 0x12504f790> model using joblib.\n",
      "INFO:mlexpy.processor:Dumped <mlexpy.processor.FeatureReducer object at 0x12504f790> to: /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/feature_reducer/6_featurereducer\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.experiment:Training over 12 features (Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'petal_area', 'sepal_area', 'sepal_length_standardscaler',\n",
      "       'sepal_width_standardscaler', 'petal_length_standardscaler',\n",
      "       'petal_width_standardscaler', 'petal_area_standardscaler',\n",
      "       'sepal_area_standardscaler'],\n",
      "      dtype='object')) and 97 examples.\n",
      "INFO:mlexpy.experiment:Performing standard model training.\n",
      "/Users/NathanSankary/.pyenv/versions/3.9.5/envs/test/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "INFO:mlexpy.experiment:Model trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data are of size (97, 12), the test data are (53, 12).\n",
      "\n",
      "The f1_macro score is: \n",
      " 0.9237472766884531.\n",
      "\n",
      "The f1_micro score is: \n",
      " 0.9245283018867925.\n",
      "\n",
      "The f1_weighted score is: \n",
      " 0.9245283018867925.\n",
      "\n",
      "The log_loss score is: \n",
      " 1.4255250124734131.\n",
      "\n",
      "The balanced_accuracy score is: \n",
      " 0.9237472766884531.\n",
      "\n",
      "The accuracy score is: \n",
      " 0.9245283018867925.\n",
      "\n",
      "The confusion_matrix score is: \n",
      " [[18  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 16]].\n",
      "\n",
      "The classification_report score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.92        53\n",
      "   macro avg       0.92      0.92      0.92        53\n",
      "weighted avg       0.92      0.92      0.92        53\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# All we need to do is change the method that is called to perform our data processing below\n",
    "from from_module_example import IrisPipeline as IrisPipeImport\n",
    "\n",
    "# Again, reset our seeds...\n",
    "model_rs = np.random.RandomState(MODEL_SEED)\n",
    "\n",
    "\n",
    "# Define the experiment\n",
    "imported_experiment = experiment.ClassifierExperiment(\n",
    "    train_setup=experiment_setup.train_data,\n",
    "    test_setup=experiment_setup.test_data,\n",
    "    cv_split_count=20,\n",
    "    model_tag=\"example_development_model\",\n",
    "    process_tag=\"example_development_process\",\n",
    "    model_dir=Path.cwd()\n",
    ")\n",
    "\n",
    "imported_experiment.set_pipeline(IrisPipeImport)\n",
    "\n",
    "# Now begin the experimentation, however, we here provide a string corresponding to a method name\n",
    "# to use to do the data processing.\n",
    "#  Not providing any process_method_str value will default to using \"process_data\"\n",
    "processed_datasets = imported_experiment.process_data(process_method_str=\"process_data_keep_all_columns\")\n",
    "\n",
    "# ... then train the model...\n",
    "trained_model = imported_experiment.train_model(\n",
    "    SGDClassifier(random_state=model_rs, loss=\"log\"),  # This is why we have 2 different random states...\n",
    "    processed_datasets,\n",
    "    # model_algorithm.hyperparams,  # If this is passed, then cross validation search is performed, but slow.\n",
    ")\n",
    "\n",
    "# Get the predictions and evaluate the performance.\n",
    "predictions = imported_experiment.predict(processed_datasets, trained_model)\n",
    "class_probabilities = imported_experiment.predict(processed_datasets, trained_model, proba=True)\n",
    "results = imported_experiment.evaluate_predictions(\n",
    "    processed_datasets.test_data.labels,\n",
    "    predictions=predictions,\n",
    "    class_probabilities=class_probabilities,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using all of the data results in better scored for the `SGDClassifier`. (We confrim that the data was processed differently looking at the log of the train and test data shape (`The train data are of size (97, 12), the test data are (53, 12).`))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (default, Oct 22 2022, 19:18:33) \n[Clang 11.0.3 (clang-1103.0.32.29)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7d53b7080da918b862bf2b02e1f266275bbc172f0f94ff6a82790353fa275a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
