{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example `mlxpy` usage on the iris dataset for multi-class classification using a RandomForest and SGDClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load the dataset, models, and mlexpy modules...\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from sklearn.datasets import load_iris\n",
    "from mlexpy import experiment, pipeline_utils, processor\n",
    "\n",
    "from typing import List, Optional, Union, Callable, Type\n",
    "\n",
    "# load a random forest and sgd classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# and numpy, pandas\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, an example of the general method flow with `mlexpy` (as described in the `README`):\n",
    "1. Load in the dataset\n",
    "2. Create your training and testing set split -- this results in an imutable named tuple structure termed an `ExperimentSetup`, this is made up of 2 `MLSetup` named tuples. Each `MLSetup` named tuple has 2 attributes, a `.obs` attribute,  and a `.labels` attribute. In essence the `.obs` attribute is your feature set (in `mlexpy` this is a pandas DataFrame, and the `.labels` is a pandas Series). An `ExperimentSetup` thus contains an `MLSetup` to use for training, and an `MLSetup` to use _purely_ for testing. This is meant to simply, and in pythonic clear language differentiate the training data (as `ExpiramentSetup.training_data`) and the test data (`ExperimentSetup.test_data`).\n",
    "    - Note: `mlexpy` defers to using a stratified train test split to retain class imbalance / class proporting in training at testing.\n",
    "3. Defing a class to do the data processing / feature engineering that inherits the `mlexpy.processor.ProcessPipelineBase` class; and a class to do the model training that inherits the `mlexpy.expirament.ClassifierExpiramentBase` class. (The explicit notebook cells will better outline this usage.)\n",
    "\n",
    "    - `mlexpy` operates in an object oriented framework. These baseclasses are built to carry a large amount of convieneint, clear, and reproducable behavior.\n",
    "\n",
    "4. Perform your feature engineering, and perform your model training.\n",
    "5. Evaluate your model.\n",
    "\n",
    "### (1) We will see how this works with all of your dev in a jupyter notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    0\n",
      "sepal width (cm)     0\n",
      "petal length (cm)    0\n",
      "petal width (cm)     0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# First, set the random seed(s) for the exprament\n",
    "MODEL_SEED = 10\n",
    "PROCESS_SEED = 100\n",
    "\n",
    "model_rs = np.random.RandomState(MODEL_SEED)\n",
    "process_rs = np.random.RandomState(PROCESS_SEED)\n",
    "\n",
    "# First, read in the dataset as a dataframe. Because mlexpy is meant to be an exploratory/experimental tool, \n",
    "# dataframes are preferred for their readability.\n",
    "data = load_iris(as_frame=True)\n",
    "features = data[\"data\"]\n",
    "labels = data[\"target\"]\n",
    "\n",
    "# We want to look at the dataset for any faulty records...\n",
    "print(features.isna().sum())\n",
    "\n",
    "# Spoiler -- there are none in the features. Next look in the labels...\n",
    "print(labels.isna().sum())\n",
    "\n",
    "# Spoiler -- none again, so we use all data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels are 35.33% of the original data (97).\n",
      "Test labels are 64.67% of the original data (53).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, generate the ExperimentSetup object, that splits the dataset for training and testing.\n",
    "experiment_setup = pipeline_utils.get_stratified_train_test_data(train_data=features, label_data=labels, test_frac=0.35, random_state=process_rs)\n",
    "\n",
    "# This provides us with a named tuple, with attributes of .train_data and .test_data \n",
    "# each one with attributes of .obs and .labels. For example...\n",
    "train_label_count = experiment_setup.train_data.labels.shape[0]\n",
    "test_label_count = experiment_setup.test_data.labels.shape[0]\n",
    "total_data_count = features.shape[0]\n",
    "\n",
    "print(f\"Train labels are {round((total_data_count - train_label_count) / total_data_count * 100, 2)}% of the original data ({train_label_count}).\")\n",
    "print(f\"Test labels are {round((total_data_count - test_label_count) / total_data_count * 100, 2)}% of the original data ({test_label_count}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, define the processing class. This inherits from the `ProcessPipelineBase` class. \n",
    "# For minimal functionality, this class simply needs the `.process_data()` method to be defined. Not adding \n",
    "# code for this class will result in a `NotImplementedError`.\n",
    "\n",
    "# The following shows an example of how to use this class:\n",
    "class IrisPipeline(processor.ProcessPipelineBase):\n",
    "    def __init__(\n",
    "        # All of the Optional arguments are not strictly necessary but shown for brevity.\n",
    "        self, \n",
    "        process_tag: str = \"iris_development\", \n",
    "        model_dir = None, \n",
    "        model_storage_function = None, \n",
    "        model_loading_function = None\n",
    "        ) -> None:\n",
    "        super().__init__(process_tag, model_dir, model_storage_function, model_loading_function)\n",
    "\n",
    "    # Now -- define the .process_data() method.\n",
    "    def process_data(self, df: pd.DataFrame, training: bool = True) -> pd.DataFrame:\n",
    "        # Now, simply do all feature engineering in this method, and return the final data/feature set to perform\n",
    "        # predictions on.\n",
    "\n",
    "        # Imagine we have 1 desired feature to engineer, petal/sepal area, and then normalize the feature values.\n",
    "        # We need to pay attention in the normalizing step, because we can ONLY apply the normalize to the test\n",
    "        # set, thus we will have a fork in the process when doing the feature normalization. \n",
    "        \n",
    "        # In order to easily maintain reproducibility in data processing, any model based feature engineering (such\n",
    "        # as normalization) is done by creating a specific data structure storing the order of steps for processing each column, \n",
    "        # and the model that should be applied. This is somewhat similar to the ColumnTransformer in sklearn.\n",
    "\n",
    "        # Model based features are handled in the .fit_model_based_features() method, described below.\n",
    "         \n",
    "        # Lets begin:\n",
    "\n",
    "        # Do a copy of the passed df\n",
    "        df = df.copy()\n",
    "\n",
    "        # First, compute the petal / sepal areas (but make the columns simpler)\n",
    "        df.columns = [col.replace(\" \", \"_\").strip(\"_(cm)\") for col in df.columns]\n",
    "\n",
    "        for object in [\"petal\", \"sepal\"]:\n",
    "            df[f\"{object}_area\"] = df[f\"{object}_length\"] * df[f\"{object}_width\"]\n",
    "\n",
    "        # Now perform the training / testing dependent feature processing. This is why a `training` boolean is passed.\n",
    "        if training:\n",
    "            # Now FIT all of the model based features...\n",
    "            self.fit_model_based_features(df)\n",
    "            # ... and get the results of a transformation of all model based features.\n",
    "            model_features = self.transform_model_based_features(df)\n",
    "        else:\n",
    "            # Here we can ONLY apply the transformation\n",
    "            model_features = self.transform_model_based_features(df)\n",
    "\n",
    "        # Imagine we only want to use ONLY the scaled features for prediction, then we retrieve only the scaled columns.\n",
    "        # (This is easy because the columns are renamed with the model name in the column name)\n",
    "        prediction_df = model_features[[col for col in model_features if \"standardscaler\" in col.lower()]]\n",
    "\n",
    "        return prediction_df\n",
    "\n",
    "    def fit_model_based_features(self, df: pd.DataFrame) -> None:\n",
    "        # Here we do any processing of columns that will require a model based transformation / engineering.\n",
    "\n",
    "        # In this case, simply fit a standard (normalization) scaler to the numerical columns. \n",
    "        # This case will result in additional columns on the dataframe named as \n",
    "        # \"<original-column-name>_StandardScaler()\".\n",
    "\n",
    "        # Note: there are no returned values for this method, the result is an update in the self.column_transformations dictionary\n",
    "        for column in df.columns:\n",
    "            if df[column].dtype not in (\"float\", \"int\"):\n",
    "                continue\n",
    "            self.fit_scaler(df[column], standard_scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/iris_development/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length_standardscaler()</th>\n",
       "      <th>sepal_width_standardscaler()</th>\n",
       "      <th>petal_length_standardscaler()</th>\n",
       "      <th>petal_width_standardscaler()</th>\n",
       "      <th>petal_area_standardscaler()</th>\n",
       "      <th>sepal_area_standardscaler()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2.552306</td>\n",
       "      <td>1.775990</td>\n",
       "      <td>1.508830</td>\n",
       "      <td>1.061415</td>\n",
       "      <td>1.551161</td>\n",
       "      <td>3.572511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.316317</td>\n",
       "      <td>-0.117098</td>\n",
       "      <td>0.617499</td>\n",
       "      <td>0.783903</td>\n",
       "      <td>0.651933</td>\n",
       "      <td>0.143745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.553235</td>\n",
       "      <td>-0.117098</td>\n",
       "      <td>0.379811</td>\n",
       "      <td>0.367633</td>\n",
       "      <td>0.184243</td>\n",
       "      <td>-0.470624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.688982</td>\n",
       "      <td>-0.827006</td>\n",
       "      <td>0.855188</td>\n",
       "      <td>0.922659</td>\n",
       "      <td>0.934354</td>\n",
       "      <td>-0.154663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.180570</td>\n",
       "      <td>-0.353734</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>0.090120</td>\n",
       "      <td>-0.107215</td>\n",
       "      <td>-0.374081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length_standardscaler()  sepal_width_standardscaler()  \\\n",
       "131                       2.552306                      1.775990   \n",
       "127                       0.316317                     -0.117098   \n",
       "84                       -0.553235                     -0.117098   \n",
       "111                       0.688982                     -0.827006   \n",
       "96                       -0.180570                     -0.353734   \n",
       "\n",
       "     petal_length_standardscaler()  petal_width_standardscaler()  \\\n",
       "131                       1.508830                      1.061415   \n",
       "127                       0.617499                      0.783903   \n",
       "84                        0.379811                      0.367633   \n",
       "111                       0.855188                      0.922659   \n",
       "96                        0.201545                      0.090120   \n",
       "\n",
       "     petal_area_standardscaler()  sepal_area_standardscaler()  \n",
       "131                     1.551161                     3.572511  \n",
       "127                     0.651933                     0.143745  \n",
       "84                      0.184243                    -0.470624  \n",
       "111                     0.934354                    -0.154663  \n",
       "96                     -0.107215                    -0.374081  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As an example, lets look at the outputs of the `.process_data()` method.\n",
    "iris_processor = IrisPipeline(model_dir=Path.cwd())  # set the model path to the examples directory\n",
    "\n",
    "# now run the process_data method\n",
    "processed_df = iris_processor.process_data(df=experiment_setup.train_data.obs.copy(), training=True)\n",
    "\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, define the IrisExperiment to inherit from the ClassifierExperimentBase class.\n",
    "#  This functionality works similarly to the `ProcessPipelineBase` class where an experiment is instantiated\n",
    "# as a class, inheriting a variety of experimental tooling.\n",
    "\n",
    "# We need to define 1 method for our child class, shown below, to handle the training and testing data processing outlined in \n",
    "# our IrisPipeline class\n",
    "\n",
    "class IrisExperiment(experiment.ClassifierExperimentBase):\n",
    "    def __init__(\n",
    "        self, \n",
    "        train_setup: pipeline_utils.MLSetup, \n",
    "        test_setup: pipeline_utils.MLSetup, \n",
    "        cv_split_count: int, \n",
    "        rnd_int: int = 100, \n",
    "        model_dir: Optional[Union[str, Path]] = None, \n",
    "        model_storage_function: Optional[Callable] = None, \n",
    "        model_loading_function: Optional[Callable] = None, \n",
    "        model_tag: str = \"example_development_model\",\n",
    "        process_tag: str = \"example_development_process\"\n",
    "        ) -> None:\n",
    "        super().__init__(train_setup, test_setup, cv_split_count, rnd_int, model_dir, model_storage_function, model_loading_function, model_tag, process_tag)\n",
    "\n",
    "\n",
    "    def process_data(\n",
    "        self,\n",
    "        process_method_str: str = \"process_data\"\n",
    "    ) -> pipeline_utils.ExperimentSetup:\n",
    "\n",
    "\n",
    "        # Now do the data processing on the method defined in process_method_str.\n",
    "        process_method = getattr(self.pipeline, process_method_str)\n",
    "        train_df = process_method(self.training.obs, training=True)\n",
    "        test_df = process_method(self.testing.obs, training=False)\n",
    "\n",
    "        print(\n",
    "            f\"The train data are of size {train_df.shape}, the test data are {test_df.shape}.\"\n",
    "        )\n",
    "\n",
    "        assert (\n",
    "            len(set(train_df.index).intersection(set(test_df.index))) == 0\n",
    "        ), \"There are duplicated indices in the train and test set.\"\n",
    "\n",
    "        return pipeline_utils.ExperimentSetup(\n",
    "            pipeline_utils.MLSetup(\n",
    "                train_df,\n",
    "                self.training.labels,\n",
    "            ),\n",
    "            pipeline_utils.MLSetup(\n",
    "                test_df,\n",
    "                self.testing.labels,\n",
    "            ),\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.experiment:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.experiment:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples/example_development_process. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.experiment:Performing standard model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data are of size (97, 6), the test data are (53, 6).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:Model trained\n"
     ]
    }
   ],
   "source": [
    "# Now, our \"work\" is done, lets pass our data through this process! Lets try using a randomforest model\n",
    "\n",
    "# Define the experiment\n",
    "experiment_obj = IrisExperiment(\n",
    "    train_setup=experiment_setup.train_data,\n",
    "    test_setup=experiment_setup.test_data,\n",
    "    cv_split_count=20,\n",
    "    model_tag=\"example_development_model\",\n",
    "    process_tag=\"example_development_process\",\n",
    "    model_dir=Path.cwd()\n",
    ")\n",
    "\n",
    "# Set the pipeline attribute to use\n",
    "experiment_obj.set_pipeline(IrisPipeline)\n",
    "\n",
    "# Now begin the experimentation, start with performing the data processing...\n",
    "processed_datasets = experiment_obj.process_data()\n",
    "\n",
    "# ... then train our model...\n",
    "trained_model = experiment_obj.train_model(\n",
    "    RandomForestClassifier(random_state=model_rs),  # This is why we have 2 different random states...\n",
    "    processed_datasets,\n",
    "    # model_algorithm.hyperparams,  # If this is passed, then cross validation search is performed, but slow.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The f1_macro score is: \n",
      " 0.9558404558404558.\n",
      "\n",
      "The f1_micro score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The f1_weighted score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The log_loss score is: \n",
      " 0.08168998066053094.\n",
      "\n",
      "The balanced_accuracy score is: \n",
      " 0.9558404558404558.\n",
      "\n",
      "The accuracy score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The confusion_matrix score is: \n",
      " [[22  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 17]].\n",
      "\n",
      "The classification_report score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.96        53\n",
      "   macro avg       0.96      0.96      0.96        53\n",
      "weighted avg       0.96      0.96      0.96        53\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Now, evaluate the predictions, ClassificationExperimentBase provides some standard classification metrics\n",
    "# and evaluations.\n",
    "\n",
    "# Get the predictions and evaluate the performance.\n",
    "predictions = experiment_obj.predict(processed_datasets, trained_model)\n",
    "class_probabilities = experiment_obj.predict(processed_datasets, trained_model, proba=True)\n",
    "results = experiment_obj.evaluate_predictions(\n",
    "    processed_datasets.test_data.labels,\n",
    "    predictions=predictions,\n",
    "    class_probabilities=class_probabilities,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Next, how this same process might look when developing as modules. \n",
    "We now use the exact same model and dataset, however use the imported modules as our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.experiment:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.experiment:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples/example_development_process. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.experiment:Performing standard model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data are of size (97, 6), the test data are (53, 6).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:Model trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The f1_macro score is: \n",
      " 0.9558404558404558.\n",
      "\n",
      "The f1_micro score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The f1_weighted score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The log_loss score is: \n",
      " 0.08168998066053094.\n",
      "\n",
      "The balanced_accuracy score is: \n",
      " 0.9558404558404558.\n",
      "\n",
      "The accuracy score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The confusion_matrix score is: \n",
      " [[22  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 17]].\n",
      "\n",
      "The classification_report score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.96        53\n",
      "   macro avg       0.96      0.96      0.96        53\n",
      "weighted avg       0.96      0.96      0.96        53\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# The only change is that we need to now import the classes we developed above classes.\n",
    "# Rename them for clarity of what is doing what\n",
    "from from_module_example import IrisExperiment as IrisExpImport\n",
    "from from_module_example import IrisPipeline as IrisPipeImport\n",
    "\n",
    "# First, reset our seeds...\n",
    "model_rs = np.random.RandomState(MODEL_SEED)\n",
    "\n",
    "\n",
    "# Define the experiment\n",
    "imported_experiment = IrisExpImport(\n",
    "    train_setup=experiment_setup.train_data,\n",
    "    test_setup=experiment_setup.test_data,\n",
    "    cv_split_count=20,\n",
    "    model_tag=\"example_development_model\",\n",
    "    process_tag=\"example_development_process\",\n",
    "    model_dir=Path.cwd()\n",
    ")\n",
    "\n",
    "# Set the pipeline to use\n",
    "imported_experiment.set\n",
    "\n",
    "# Now begin the experimentation, start with performing the data processing...\n",
    "processed_datasets = self.pipeline()\n",
    "\n",
    "# ... then train the model...\n",
    "trained_model = imported_experiment.train_model(\n",
    "    RandomForestClassifier(random_state=model_rs),  # This is why we have 2 different random states...\n",
    "    processed_datasets,\n",
    "    # model_algorithm.hyperparams,  # If this is passed, then cross validation search is performed, but slow.\n",
    ")\n",
    "\n",
    "# Get the predictions and evaluate the performance.\n",
    "predictions = imported_experiment.predict(processed_datasets, trained_model)\n",
    "class_probabilities = imported_experiment.predict(processed_datasets, trained_model, proba=True)\n",
    "results = imported_experiment.evaluate_predictions(\n",
    "    processed_datasets.test_data.labels,\n",
    "    predictions=predictions,\n",
    "    class_probabilities=class_probabilities,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And you can se that we get the exact same results when using the imported modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Do the same process using this time and `SGDClassifier`\n",
    "\n",
    "This time, all we need to do is change the model that is passed when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.experiment:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.experiment:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples/example_development_process. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.experiment:Performing standard model training.\n",
      "/Users/NathanSankary/.pyenv/versions/3.9.5/envs/lang/envs/mlexpy/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "INFO:mlexpy.experiment:Model trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data are of size (97, 6), the test data are (53, 6).\n",
      "\n",
      "The f1_macro score is: \n",
      " 0.9558404558404558.\n",
      "\n",
      "The f1_micro score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The f1_weighted score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The log_loss score is: \n",
      " 0.1955833766845036.\n",
      "\n",
      "The balanced_accuracy score is: \n",
      " 0.9558404558404558.\n",
      "\n",
      "The accuracy score is: \n",
      " 0.9622641509433962.\n",
      "\n",
      "The confusion_matrix score is: \n",
      " [[22  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1 17]].\n",
      "\n",
      "The classification_report score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.96        53\n",
      "   macro avg       0.96      0.96      0.96        53\n",
      "weighted avg       0.96      0.96      0.96        53\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# The only change is that we need to now import the classes we developed above classes.\n",
    "# Rename them for clarity of what is doing what\n",
    "\n",
    "# Again, reset our seeds...\n",
    "model_rs = np.random.RandomState(MODEL_SEED)\n",
    "\n",
    "\n",
    "# Define the experiment\n",
    "imported_experiment = IrisExpImport(\n",
    "    train_setup=experiment_setup.train_data,\n",
    "    test_setup=experiment_setup.test_data,\n",
    "    cv_split_count=20,\n",
    "    model_tag=\"example_development_model\",\n",
    "    process_tag=\"example_development_process\",\n",
    "    model_dir=Path.cwd()\n",
    ")\n",
    "\n",
    "# Now begin the experimentation, start with performing the data processing...\n",
    "processed_datasets = imported_experiment.process_data()\n",
    "\n",
    "# ... then train the model...\n",
    "trained_model = imported_experiment.train_model(\n",
    "    SGDClassifier(random_state=model_rs, loss=\"log\"),  # This is why we have 2 different random states...\n",
    "    processed_datasets,\n",
    "    # model_algorithm.hyperparams,  # If this is passed, then cross validation search is performed, but slow.\n",
    ")\n",
    "\n",
    "# Get the predictions and evaluate the performance.\n",
    "predictions = imported_experiment.predict(processed_datasets, trained_model)\n",
    "class_probabilities = imported_experiment.predict(processed_datasets, trained_model, proba=True)\n",
    "results = imported_experiment.evaluate_predictions(\n",
    "    processed_datasets.test_data.labels,\n",
    "    predictions=predictions,\n",
    "    class_probabilities=class_probabilities,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Now what if we wanted to use a different set of columns (ex. ALL cols not only the scaled columns)?\n",
    "We do that simply by re-defining the method to process our data. We can either, overwrite the method with the change, or compute a new process_data method for this specific case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlexpy.experiment:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.experiment:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.experiment:setting the model path to /Users/NathanSankary/git/mlexpy/examples. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:No model storage function provided. Using the default class method (joblib, or .store_model native method).\n",
      "INFO:mlexpy.processor:No model loading function provided. Using the default class method (joblib, or .load_model native method).\n",
      "INFO:mlexpy.processor:setting the model path to /Users/NathanSankary/git/mlexpy/examples/example_development_process. (Converting from string to pathlib.Path)\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_length.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_width.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to petal_area.\n",
      "INFO:mlexpy.processor:Fitting a standard scaler to sepal_area.\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_length\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_width\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/petal_area\n",
      "INFO:mlexpy.processor:Dumping 1 models to /Users/NathanSankary/git/mlexpy/examples/example_development_process/example_development_process/sepal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_length\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_width\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to petal_area\n",
      "INFO:mlexpy.processor:Applying the StandardScaler() to sepal_area\n",
      "INFO:mlexpy.experiment:Performing standard model training.\n",
      "/Users/NathanSankary/.pyenv/versions/3.9.5/envs/lang/envs/mlexpy/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "INFO:mlexpy.experiment:Model trained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data are of size (97, 12), the test data are (53, 12).\n",
      "\n",
      "The f1_macro score is: \n",
      " 0.9781305114638448.\n",
      "\n",
      "The f1_micro score is: \n",
      " 0.9811320754716981.\n",
      "\n",
      "The f1_weighted score is: \n",
      " 0.9812119397025056.\n",
      "\n",
      "The log_loss score is: \n",
      " 0.139554071082744.\n",
      "\n",
      "The balanced_accuracy score is: \n",
      " 0.9814814814814815.\n",
      "\n",
      "The accuracy score is: \n",
      " 0.9811320754716981.\n",
      "\n",
      "The confusion_matrix score is: \n",
      " [[22  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 17]].\n",
      "\n",
      "The classification_report score is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.98        53\n",
      "   macro avg       0.98      0.98      0.98        53\n",
      "weighted avg       0.98      0.98      0.98        53\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# All we need to do is change the method that is called to perform our data processing below\n",
    "from from_module_example import IrisPipeline as IrisPipeImport\n",
    "\n",
    "# Again, reset our seeds...\n",
    "model_rs = np.random.RandomState(MODEL_SEED)\n",
    "\n",
    "\n",
    "# Define the experiment\n",
    "imported_experiment = IrisExpImport(\n",
    "    train_setup=experiment_setup.train_data,\n",
    "    test_setup=experiment_setup.test_data,\n",
    "    cv_split_count=20,\n",
    "    model_tag=\"example_development_model\",\n",
    "    process_tag=\"example_development_process\",\n",
    "    model_dir=Path.cwd()\n",
    ")\n",
    "\n",
    "# Now begin the experimentation, however, we here provide a string corresponding to a method name\n",
    "# to use to do the data processing.\n",
    "#  Not providing any process_method_str value will default to using \"process_data\"\n",
    "processed_datasets = imported_experiment.process_data(process_method_str=\"process_data_keep_all_columns\")\n",
    "\n",
    "# ... then train the model...\n",
    "trained_model = imported_experiment.train_model(\n",
    "    SGDClassifier(random_state=model_rs, loss=\"log\"),  # This is why we have 2 different random states...\n",
    "    processed_datasets,\n",
    "    # model_algorithm.hyperparams,  # If this is passed, then cross validation search is performed, but slow.\n",
    ")\n",
    "\n",
    "# Get the predictions and evaluate the performance.\n",
    "predictions = imported_experiment.predict(processed_datasets, trained_model)\n",
    "class_probabilities = imported_experiment.predict(processed_datasets, trained_model, proba=True)\n",
    "results = imported_experiment.evaluate_predictions(\n",
    "    processed_datasets.test_data.labels,\n",
    "    predictions=predictions,\n",
    "    class_probabilities=class_probabilities,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using all of the data results in better scored for the `SGDClassifier`. (We confrim that the data was processed differently looking at the log of the train and test data shape (`The train data are of size (97, 12), the test data are (53, 12).`))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('mlexpy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (default, Oct 22 2022, 19:18:33) \n[Clang 11.0.3 (clang-1103.0.32.29)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a3bf03e9bc503568ad4247b4207894faa64f010818fdf63117cea0fa36d0f36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
